<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
    <header>
        <h1><a href="https://learn.microsoft.com/en-us/training/modules/introduction-computer-vision/">Computer Vision Fundamentals</a></h1>
    </header>
    <hr class="section-divider">
    <main>
        <section id="multiple-choice-questions">
            <section class="question-group">
                <h4>1. What is the primary focus of computer vision as a core area of AI?</h4>
                <ol type="a">
                    <li>Enabling AI applications to generate text.</li>
                    <li>Enabling AI applications to "see" and understand the world.</li>
                    <li>Enabling AI applications to perform complex calculations.</li>
                    <li>Enabling AI applications to process audio signals.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>2. What types of inputs do computers process in computer vision to emulate human visual perception?</h4>
                <ol type="a">
                    <li>Only live feeds.</li>
                    <li>Only digital photographs.</li>
                    <li>Only videos.</li>
                    <li>Live feeds, digital photographs, or videos.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: d)</p>
                </details>
            </section><section class="question-group">
                <h4>3. Computer vision aims to extract ______ or actionable insights from images.</h4>
                <ol type="a">
                    <li>Random patterns</li>
                    <li>Meaning</li>
                    <li>Raw pixel data</li>
                    <li>Color palettes</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>4. What is one of the foundational elements explored in modern computer vision solutions according to the introduction?</h4>
                <ol type="a">
                    <li>Database management.</li>
                    <li>Network security protocols.</li>
                    <li>Core AI principles.</li>
                    <li>Foundational elements of modern computer vision solutions.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: d)</p>
                </details>
            </section><section class="question-group">
                <h4>5. What is computer vision often compared to in human terms?</h4>
                <ol type="a">
                    <li>Human hearing.</li>
                    <li>Human memory.</li>
                    <li>Human visual perception.</li>
                    <li>Human speech.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>6. What is a key challenge computer vision aims to overcome for AI applications?</h4>
                <ol type="a">
                    <li>Understanding complex mathematical equations.</li>
                    <li>Translating text from one language to another.</li>
                    <li>Interpreting visual information from the world.</li>
                    <li>Generating new creative content.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>7. How does computer vision allow AI to interact with the visual world?</h4>
                <ol type="a">
                    <li>By converting images into audio.</li>
                    <li>By allowing AI to "see" and interpret visual data.</li>
                    <li>By enabling AI to create original images.</li>
                    <li>By only recognizing predefined objects.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>8. What kind of data does computer vision primarily work with?</h4>
                <ol type="a">
                    <li>Numerical data.</li>
                    <li>Textual data.</li>
                    <li>Visual data (images, videos).</li>
                    <li>Audio data.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>9. Which of the following is NOT explicitly mentioned as a type of input for computer vision systems?</h4>
                <ol type="a">
                    <li>Digital photographs.</li>
                    <li>Live feeds.</li>
                    <li>Spreadsheets.</li>
                    <li>Videos.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>10. What is the overarching goal of computer vision in AI?</h4>
                <ol type="a">
                    <li>To replicate human hearing.</li>
                    <li>To empower AI with understanding of speech.</li>
                    <li>To equip AI with the ability to perceive and understand visual information.</li>
                    <li>To facilitate human-robot interaction via touch.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>11. How are images fundamentally represented as data for computer programs in computer vision?</h4>
                <ol type="a">
                    <li>As abstract concepts.</li>
                    <li>As sound waves.</li>
                    <li>As arrays of pixels.</li>
                    <li>As lines of code.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>12. In a grayscale image, what does each pixel value typically represent?</h4>
                <ol type="a">
                    <li>Color hue.</li>
                    <li>Brightness or intensity.</li>
                    <li>Transparency.</li>
                    <li>Sound frequency.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>13. What is the typical range of numeric values for pixels in a grayscale image?</h4>
                <ol type="a">
                    <li>0 to 1.</li>
                    <li>-1 to 1.</li>
                    <li>0 to 255.</li>
                    <li>1 to 100.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>14. How are color images represented in terms of pixel arrays?</h4>
                <ol type="a">
                    <li>By a single channel like grayscale images.</li>
                    <li>By four channels (Red, Green, Blue, Alpha).</li>
                    <li>By three channels, typically Red, Green, and Blue (RGB).</li>
                    <li>By a completely different data structure than grayscale images.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>15. Which of the following is NOT a category of computer vision capabilities mentioned in the overview?</h4>
                <ol type="a">
                    <li>Image analysis.</li>
                    <li>Spatial analysis.</li>
                    <li>Audio synthesis.</li>
                    <li>Optical character recognition (OCR).</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>16. What capability involves identifying and locating objects within an image?</h4>
                <ol type="a">
                    <li>Facial recognition.</li>
                    <li>Optical character recognition (OCR).</li>
                    <li>Image analysis.</li>
                    <li>Spatial analysis.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>17. Which computer vision capability focuses on identifying individuals based on their unique facial features?</h4>
                <ol type="a">
                    <li>Image analysis.</li>
                    <li>Spatial analysis.</li>
                    <li>Facial recognition.</li>
                    <li>Optical character recognition.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>18. What is the purpose of Optical Character Recognition (OCR)?</h4>
                <ol type="a">
                    <li>To convert spoken words into text.</li>
                    <li>To convert images of text into machine-encoded text.</li>
                    <li>To analyze the spatial arrangement of objects.</li>
                    <li>To classify images into predefined categories.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>19. If an image is 7x7 pixels and grayscale, how many numeric pixel values would represent it?</h4>
                <ol type="a">
                    <li>7.</li>
                    <li>14.</li>
                    <li>49.</li>
                    <li>147.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>20. For a color image of 7x7 pixels, approximately how many numeric values are typically used to represent it?</h4>
                <ol type="a">
                    <li>49 (7x7).</li>
                    <li>98 (7x7x2).</li>
                    <li>147 (7x7x3).</li>
                    <li>196 (7x7x4).</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>21. How are image processing tasks typically performed, as explained in the documentation?</h4>
                <ol type="a">
                    <li>Using random number generators.</li>
                    <li>Using filters.</li>
                    <li>Using direct pixel manipulation without a structured approach.</li>
                    <li>Using audio signals.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>22. What defines a filter in image processing?</h4>
                <ol type="a">
                    <li>A single numeric value.</li>
                    <li>An array of pixel values called a filter kernel.</li>
                    <li>A text string.</li>
                    <li>A color code.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>23. What is the process of applying a filter kernel across an image called?</h4>
                <ol type="a">
                    <li>Pixelation.</li>
                    <li>Normalization.</li>
                    <li>Convolution.</li>
                    <li>Segmentation.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>24. In convolution, how are new pixel values created?</h4>
                <ol type="a">
                    <li>By averaging all pixel values in the image.</li>
                    <li>By randomly assigning new values.</li>
                    <li>By multiplying image pixel values by corresponding kernel weights and summing them.</li>
                    <li>By only considering the central pixel value.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>25. Why are resulting values in image processing adjusted to fit within the 0 to 255 pixel range?</h4>
                <ol type="a">
                    <li>To increase computational complexity.</li>
                    <li>To ensure they correspond to standard grayscale or color channel representations.</li>
                    <li>To make the image appear blurry.</li>
                    <li>To reduce the image file size.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>26. What is "padding" used for in image processing, especially with filters?</h4>
                <ol type="a">
                    <li>To add color to a grayscale image.</li>
                    <li>To increase the resolution of an image.</li>
                    <li>To handle the outside edge of pixels during convolution.</li>
                    <li>To reduce the number of pixels in an image.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>27. What effect does a Laplace filter typically have on an image?</h4>
                <ol type="a">
                    <li>It blurs the image.</li>
                    <li>It sharpens the image.</li>
                    <li>It highlights the edges of shapes.</li>
                    <li>It inverts the colors.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>28. What is another common name for image manipulation using filters and convolution?</h4>
                <ol type="a">
                    <li>Linear regression.</li>
                    <li>Convolutional filtering.</li>
                    <li>Statistical analysis.</li>
                    <li>Image compression.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>29. Besides highlighting edges, what other effects can various filters achieve in image processing?</h4>
                <ol type="a">
                    <li>Only blurring.</li>
                    <li>Only sharpening.</li>
                    <li>Effects like blurring or sharpening.</li>
                    <li>Only color inversion.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>30. How does image processing differ from computer vision's ultimate goal?</h4>
                <ol type="a">
                    <li>Image processing generates new images, while computer vision classifies them.</li>
                    <li>Image processing focuses on visual effects, while computer vision aims to extract meaning or insights.</li>
                    <li>There is no significant difference; they are interchangeable terms.</li>
                    <li>Image processing uses AI, while computer vision does not.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>31. What is the primary purpose of machine learning in computer vision, as opposed to simple image processing?</h4>
                <ol type="a">
                    <li>To apply visual effects like blurring.</li>
                    <li>To create new images from scratch.</li>
                    <li>To train models to recognize features and extract meaning or actionable insights from images.</li>
                    <li>To compress image files.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>32. Which neural network architecture is commonly used for computer vision tasks like image classification?</h4>
                <ol type="a">
                    <li>Recurrent Neural Networks (RNNs).</li>
                    <li>Generative Adversarial Networks (GANs).</li>
                    <li>Convolutional Neural Networks (CNNs).</li>
                    <li>Long Short-Term Memory (LSTM) networks.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>33. How do CNNs typically extract numeric feature maps from images?</h4>
                <ol type="a">
                    <li>By random sampling of pixels.</li>
                    <li>By applying filters.</li>
                    <li>By directly converting pixel values to labels.</li>
                    <li>By using statistical averages only.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>34. What happens to the feature maps extracted by CNN filters?</h4>
                <ol type="a">
                    <li>They are directly displayed as output.</li>
                    <li>They are discarded after extraction.</li>
                    <li>They are fed into a deep learning model to generate label predictions.</li>
                    <li>They are converted into audio signals.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>35. What is the initial state of filter kernel weights in a CNN training process?</h4>
                <ol type="a">
                    <li>They are pre-defined constants.</li>
                    <li>They are randomly generated.</li>
                    <li>They are set to zero.</li>
                    <li>They are manually programmed.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>36. How are filter kernel weights adjusted during CNN training?</h4>
                <ol type="a">
                    <li>They remain static throughout the training.</li>
                    <li>They are adjusted to improve accuracy as predictions are evaluated against known label values.</li>
                    <li>They are adjusted based on user feedback after deployment.</li>
                    <li>They are adjusted randomly at each step.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>37. What is typically fed into a CNN during the training phase to help it learn?</h4>
                <ol type="a">
                    <li>Images with unknown labels.</li>
                    <li>Only text descriptions.</li>
                    <li>Images with known labels.</li>
                    <li>Random noise patterns.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>38. What is the goal of modifying weights in a CNN during training?</h4>
                <ol type="a">
                    <li>To increase the complexity of the model.</li>
                    <li>To reduce the "loss" or error between predictions and actual labels.</li>
                    <li>To make the model run faster.</li>
                    <li>To generate more diverse output.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>39. Once a CNN model is trained, what can it be used for?</h4>
                <ol type="a">
                    <li>To generate new training data.</li>
                    <li>To modify the original input images.</li>
                    <li>To predict labels for new, unknown images.</li>
                    <li>To calculate statistical probabilities only.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>40. Which of the following best describes the process of a CNN for image classification?</h4>
                <ol type="a">
                    <li>Input images are directly converted into text.</li>
                    <li>Input images are filtered to extract features, which are then used by a deep learning model to predict labels.</li>
                    <li>Input images are manually categorized by humans after processing.</li>
                    <li>Input images are compressed without any analysis.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>41. Which neural network architecture has significantly advanced Natural Language Processing (NLP) and is now being applied to computer vision?</h4>
                <ol type="a">
                    <li>Convolutional Neural Networks (CNNs).</li>
                    <li>Recurrent Neural Networks (RNNs).</li>
                    <li>Transformers.</li>
                    <li>Generative Adversarial Networks (GANs).</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>42. How do transformers represent semantic relationships in language tokens?</h4>
                <ol type="a">
                    <li>By encoding them into numerical tables.</li>
                    <li>By encoding them into vector-based embeddings.</li>
                    <li>By converting them into audio files.</li>
                    <li>By storing them as plain text.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>43. What are "multi-modal models" designed to combine?</h4>
                <ol type="a">
                    <li>Different types of programming languages.</li>
                    <li>The success of transformers in NLP with image data.</li>
                    <li>Only numerical and audio data.</li>
                    <li>Only text and structured data.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>44. What kind of data are multi-modal models typically trained on?</h4>
                <ol type="a">
                    <li>Only unlabeled images.</li>
                    <li>Only text documents.</li>
                    <li>Vast amounts of captioned images.</li>
                    <li>Only audio recordings.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>45. What two main components do modern multi-modal vision models use to encapsulate relationships between language and image features?</h4>
                <ol type="a">
                    <li>A text encoder and a video decoder.</li>
                    <li>A language encoder and an image encoder.</li>
                    <li>Two separate image encoders.</li>
                    <li>Two separate language encoders.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>46. What is a "foundation model" in the context of modern vision models?</h4>
                <ol type="a">
                    <li>A small, specialized model for a single task.</li>
                    <li>A model pre-trained on a limited dataset for specific industries.</li>
                    <li>A pre-trained general model that can be adapted for various specialist tasks.</li>
                    <li>A model that only performs image generation.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>47. Which of the following is NOT listed as a specialist task that foundation models can be adapted for?</h4>
                <ol type="a">
                    <li>Image classification.</li>
                    <li>Object detection.</li>
                    <li>Database administration.</li>
                    <li>Image captioning.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>48. Why are multi-modal models considered at the forefront of AI?</h4>
                <ol type="a">
                    <li>Because they only require small amounts of data.</li>
                    <li>Because they can only perform a single task.</li>
                    <li>Because they combine different data types and capabilities, leading to versatile AI solutions.</li>
                    <li>Because they are simpler in architecture than older models.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>49. What role have Convolutional Neural Networks (CNNs) historically played in computer vision?</h4>
                <ol type="a">
                    <li>They were rarely used before transformers.</li>
                    <li>They have long been central, particularly for image classification and object detection.</li>
                    <li>They were only used for natural language processing.</li>
                    <li>They are a very recent development in computer vision.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>50. What is an "embedding" in the context of transformers and multi-modal models?</h4>
                <ol type="a">
                    <li>A raw pixel value.</li>
                    <li>A textual description of an image.</li>
                    <li>A vector-based representation that captures semantic relationships.</li>
                    <li>A type of filter kernel.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>51. Computer vision is a core area of which broader field?</h4>
                <ol type="a">
                    <li>Data analytics.</li>
                    <li>Cybersecurity.</li>
                    <li>Artificial Intelligence (AI).</li>
                    <li>Web development.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>52. What is the primary human sense that computer vision aims to emulate?</h4>
                <ol type="a">
                    <li>Hearing.</li>
                    <li>Touch.</li>
                    <li>Sight.</li>
                    <li>Smell.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>53. What kind of input is NOT listed as a common source for computer vision systems?</h4>
                <ol type="a">
                    <li>Live camera feeds.</li>
                    <li>Digital photographs.</li>
                    <li>Audio recordings.</li>
                    <li>Video streams.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>54. What is one of the main goals for AI applications using computer vision?</h4>
                <ol type="a">
                    <li>To create abstract art.</li>
                    <li>To write poetry.</li>
                    <li>To understand the world.</li>
                    <li>To generate random numbers.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>55. What does the introduction promise to explore regarding computer vision solutions?</h4>
                <ol type="a">
                    <li>Their financial impact.</li>
                    <li>Their historical development.</li>
                    <li>Their foundational elements.</li>
                    <li>Their ethical implications exclusively.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>56. How do computers typically "see" images?</h4>
                <ol type="a">
                    <li>By recognizing shapes directly.</li>
                    <li>By processing them as arrays of numeric pixel values.</li>
                    <li>By converting them into sound waves.</li>
                    <li>By reading their embedded text descriptions.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>57. What value represents black in an 8-bit grayscale pixel range (0-255)?</h4>
                <ol type="a">
                    <li>255.</li>
                    <li>128.</li>
                    <li>0.</li>
                    <li>Any value within the range.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>58. What value represents white in an 8-bit grayscale pixel range (0-255)?</h4>
                <ol type="a">
                    <li>0.</li>
                    <li>1.</li>
                    <li>128.</li>
                    <li>255.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: d)</p>
                </details>
            </section><section class="question-group">
                <h4>59. If a grayscale pixel has a value of 128, what does this indicate?</h4>
                <ol type="a">
                    <li>It's pure black.</li>
                    <li>It's pure white.</li>
                    <li>It's a shade of gray in the middle range.</li>
                    <li>It's an error.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>60. What distinguishes a color image's pixel representation from a grayscale image's?</h4>
                <ol type="a">
                    <li>Color images use a single, larger array.</li>
                    <li>Color images use multiple channels, each representing a primary color component.</li>
                    <li>Color images have no numerical representation.</li>
                    <li>Color images are represented by text descriptions.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>61. Which of the following is an example of an image analysis task?</h4>
                <ol type="a">
                    <li>Converting an audio file to text.</li>
                    <li>Identifying the main subject of an image.</li>
                    <li>Translating text from English to Spanish.</li>
                    <li>Generating random numbers.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>62. What does spatial analysis in computer vision involve?</h4>
                <ol type="a">
                    <li>Analyzing the emotional content of text.</li>
                    <li>Understanding the relationships between objects in an image based on their position and proximity.</li>
                    <li>Predicting stock market trends.</li>
                    <li>Generating new musical compositions.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>63. Which computer vision capability would be used to unlock a smartphone using a person's face?</h4>
                <ol type="a">
                    <li>Optical character recognition.</li>
                    <li>Image analysis.</li>
                    <li>Facial recognition.</li>
                    <li>Spatial analysis.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>64. What is the core mechanism by which images are processed using filters?</h4>
                <ol type="a">
                    <li>Simple addition of pixel values.</li>
                    <li>Random rearrangement of pixels.</li>
                    <li>Applying a filter kernel through convolution.</li>
                    <li>Directly altering image resolution.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>65. A filter kernel is best described as a:</h4>
                <ol type="a">
                    <li>Single numerical value.</li>
                    <li>Linear equation.</li>
                    <li>Small array of pixel values.</li>
                    <li>Large database.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>66. When a filter kernel is "convolved" across an image, what does this process primarily involve?</h4>
                <ol type="a">
                    <li>Deleting pixels from the image.</li>
                    <li>Multiplying pixel values by kernel weights and summing them for a new output pixel.</li>
                    <li>Copying pixels from one image to another.</li>
                    <li>Shrinking the image size.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>67. Why is "padding" often applied to the outside edge of pixels during convolutional filtering?</h4>
                <ol type="a">
                    <li>To change the image's color.</li>
                    <li>To ensure the filter can be applied to edge pixels without going out of bounds.</li>
                    <li>To make the image appear softer.</li>
                    <li>To reduce the number of calculations.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>68. If a filter is designed to blur an image, what would be the general effect on sharp edges?</h4>
                <ol type="a">
                    <li>They would become more pronounced.</li>
                    <li>They would disappear completely.</li>
                    <li>They would become softer and less defined.</li>
                    <li>They would change color.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>69. What is the primary difference in goal between image processing (using filters) and computer vision (using ML models)?</h4>
                <ol type="a">
                    <li>Image processing aims for visual effects; computer vision aims for understanding.</li>
                    <li>Image processing always uses AI; computer vision does not.</li>
                    <li>Image processing only works on color images; computer vision only on grayscale.</li>
                    <li>There is no functional difference.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: a)</p>
                </details>
            </section><section class="question-group">
                <h4>70. In the context of CNNs, what are "feature maps"?</h4>
                <ol type="a">
                    <li>Geographical maps of features.</li>
                    <li>Numeric representations extracted by filters, highlighting specific patterns in an image.</li>
                    <li>Random noise patterns.</li>
                    <li>Text files describing image content.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>71. What kind of model consumes the numeric feature maps generated by CNN filters?</h4>
                <ol type="a">
                    <li>A simple statistical model.</li>
                    <li>A deep learning model.</li>
                    <li>A traditional programming script.</li>
                    <li>A database.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>72. What is the output of a deep learning model in a CNN, given the feature maps?</h4>
                <ol type="a">
                    <li>New images.</li>
                    <li>Random numbers.</li>
                    <li>Label predictions (e.g., classifying the subject of an image).</li>
                    <li>Audio recordings.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>73. What is the purpose of comparing predictions to "known label values" during CNN training?</h4>
                <ol type="a">
                    <li>To confuse the model.</li>
                    <li>To evaluate the model's accuracy and guide weight adjustments.</li>
                    <li>To discard inaccurate predictions.</li>
                    <li>To simply record the results.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>74. What is the ultimate goal of the CNN training process?</h4>
                <ol type="a">
                    <li>To increase computational time.</li>
                    <li>To make the model perfectly recreate input images.</li>
                    <li>To create a model that can accurately predict labels for unseen images.</li>
                    <li>To generate random output.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>75. How do transformers encode language tokens to represent semantic relationships?</h4>
                <ol type="a">
                    <li>By assigning a random number to each token.</li>
                    <li>By converting them into vector-based embeddings.</li>
                    <li>By storing them as plain text files.</li>
                    <li>By converting them into audio sounds.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>76. What significant development enabled the creation of multi-modal models combining NLP and image data?</h4>
                <ol type="a">
                    <li>New types of cameras.</li>
                    <li>The success of transformer architecture in NLP.</li>
                    <li>Increased internet speed.</li>
                    <li>Development of simpler image formats.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>77. What do multi-modal models use to encapsulate relationships between natural language token embeddings and image features?</h4>
                <ol type="a">
                    <li>Only a language encoder.</li>
                    <li>Only an image encoder.</li>
                    <li>Both a language encoder and an image encoder.</li>
                    <li>A single, combined encoder.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>78. The training of multi-modal models on "vast amounts of captioned images" implies what?</h4>
                <ol type="a">
                    <li>That the images have no associated text.</li>
                    <li>That the images are paired with descriptive text.</li>
                    <li>That only a small number of images are needed.</li>
                    <li>That only uncaptioned images are used.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>79. Why are foundation models valuable in AI?</h4>
                <ol type="a">
                    <li>Because they are limited to a single, highly specific task.</li>
                    <li>Because they are small and easy to train from scratch.</li>
                    <li>Because they are pre-trained general models adaptable to various tasks.</li>
                    <li>Because they are only used for research purposes.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>80. Which of these tasks can a modern vision foundation model NOT typically be adapted for?</h4>
                <ol type="a">
                    <li>Object detection.</li>
                    <li>Image captioning.</li>
                    <li>Predicting stock prices based on news headlines.</li>
                    <li>Image tagging.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>81. What is meant by "deep learning" in the context of computer vision models?</h4>
                <ol type="a">
                    <li>Learning from very complex data.</li>
                    <li>Using neural networks with many layers to process information.</li>
                    <li>Learning in a profound philosophical way.</li>
                    <li>Learning from only a small amount of data.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>82. What is the fundamental concept behind a "neural network"?</h4>
                <ol type="a">
                    <li>A network of physical neurons in a brain.</li>
                    <li>A computational model inspired by the structure and function of biological neural networks.</li>
                    <li>A type of database.</li>
                    <li>A programming language.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>83. What happens to the "loss" value during effective CNN training?</h4>
                <ol type="a">
                    <li>It increases.</li>
                    <li>It remains constant.</li>
                    <li>It decreases.</li>
                    <li>It fluctuates randomly.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>84. What does "tagging" an image with a foundation model typically mean?</h4>
                <ol type="a">
                    <li>Adding a physical tag to the image.</li>
                    <li>Attaching relevant keywords or labels to the image's content.</li>
                    <li>Creating a copy of the image.</li>
                    <li>Resizing the image.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>85. How do multi-modal models represent both language and image information?</h4>
                <ol type="a">
                    <li>By converting all information into text.</li>
                    <li>By converting all information into images.</li>
                    <li>By encoding both into a shared vector space, allowing them to understand relationships between modalities.</li>
                    <li>By keeping them completely separate.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>86. What is a common application of image classification in computer vision?</h4>
                <ol type="a">
                    <li>Translating languages.</li>
                    <li>Identifying the primary subject of an image, e.g., a specific type of fruit.</li>
                    <li>Generating random sounds.</li>
                    <li>Creating 3D models from text.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>87. What is the role of the deep learning model in a CNN after feature extraction?</h4>
                <ol type="a">
                    <li>To modify the original image.</li>
                    <li>To generate label predictions based on the extracted features.</li>
                    <li>To apply more filters.</li>
                    <li>To reduce the image quality.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>88. What is the benefit of using pre-trained foundation models?</h4>
                <ol type="a">
                    <li>They require extensive training data for each new task.</li>
                    <li>They can be adapted to various tasks without starting training from scratch.</li>
                    <li>They are only suitable for very specific, narrow applications.</li>
                    <li>They are always less accurate than models trained from scratch.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>89. How do convolutional filters in CNNs differ from general image processing filters?</h4>
                <ol type="a">
                    <li>They are exactly the same and serve the same purpose.</li>
                    <li>CNN filters are learned during training to extract meaningful features for prediction.</li>
                    <li>CNN filters are always fixed and never change.</li>
                    <li>Image processing filters only work on color images.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>90. What does the term "fine-tuning" refer to when using foundation models?</h4>
                <ol type="a">
                    <li>Training the model from scratch on a new dataset.</li>
                    <li>Adjusting the model's parameters slightly for a specific task after pre-training.</li>
                    <li>Reducing the model's size.</li>
                    <li>Only using the model for its original pre-training task.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>91. What is a key advantage of multi-modal models over single-modality models?</h4>
                <ol type="a">
                    <li>They are much simpler to design.</li>
                    <li>They can understand and process information from different types of data (e.g., text and images) together.</li>
                    <li>They are limited to processing only one type of data.</li>
                    <li>They don't require any training data.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>92. Why are modern vision models, particularly multi-modal ones, expected to drive future advancements in AI?</h4>
                <ol type="a">
                    <li>Because they are limited to very few applications.</li>
                    <li>Because they consume less computational power.</li>
                    <li>Because of their versatility and ability to handle complex, real-world data.</li>
                    <li>Because they only work in controlled environments.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section><section class="question-group">
                <h4>93. The concept of "convolution" in image processing and CNNs refers to:</h4>
                <ol type="a">
                    <li>A type of data compression.</li>
                    <li>A mathematical operation that applies a filter (kernel) over an input to produce an output.</li>
                    <li>A method of creating random images.</li>
                    <li>A form of data storage.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>94. What is a key step in preparing an image for computer processing?</h4>
                <ol type="a">
                    <li>Converting it into a sound file.</li>
                    <li>Representing it as an array of numerical pixel values.</li>
                    <li>Printing it on paper.</li>
                    <li>Describing it verbally.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>95. In computer vision, what is the role of "understanding" the world?</h4>
                <ol type="a">
                    <li>To simply display images.</li>
                    <li>To interpret visual information, such as recognizing objects, scenes, and actions.</li>
                    <li>To convert images into 3D models without analysis.</li>
                    <li>To generate new images at random.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>96. What is the fundamental difference between a single-channel (grayscale) and a multi-channel (color) image representation?</h4>
                <ol type="a">
                    <li>Grayscale images are larger in file size.</li>
                    <li>Grayscale uses one numeric value per pixel for intensity, while color uses multiple values (e.g., RGB) to define color hues.</li>
                    <li>Color images have no pixel values.</li>
                    <li>Grayscale images are always higher resolution.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>97. Why is training a machine learning model necessary for computer vision tasks beyond basic image processing?</h4>
                <ol type="a">
                    <li>Image processing can already extract full meaning from images.</li>
                    <li>Machine learning models are needed to learn complex patterns and relationships to interpret images meaningfully.</li>
                    <li>It's just an optional step that doesn't impact performance.</li>
                    <li>Training is only for generating images, not for understanding them.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>98. What is the key innovation that transformers brought from NLP to computer vision?</h4>
                <ol type="a">
                    <li>The ability to directly process raw pixels without any feature extraction.</li>
                    <li>The concept of attention mechanisms and effective sequence modeling for longer dependencies.</li>
                    <li>The idea of using only small datasets for training.</li>
                    <li>The development of new camera technologies.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>99. How do modern vision models often serve as "foundation models"?</h4>
                <ol type="a">
                    <li>By being trained for a single, very specific task.</li>
                    <li>By providing a strong pre-trained base that can be adapted (fine-tuned) for various downstream tasks.</li>
                    <li>By being exclusively used for academic research.</li>
                    <li>By generating random output that serves as a foundation for other models.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: b)</p>
                </details>
            </section><section class="question-group">
                <h4>100. What does the term "semantic relationships" refer to in the context of language models and embeddings?</h4>
                <ol type="a">
                    <li>How words are spelled correctly.</li>
                    <li>The grammatical structure of sentences.</li>
                    <li>The meaning and conceptual connections between words or phrases.</li>
                    <li>The literal length of a word.</li>
                </ol>
                <details>
                    <summary>Show Answer</summary>
                    <p>Correct Answer: c)</p>
                </details>
            </section>
        </section>
    </main>
</body>
</html>
