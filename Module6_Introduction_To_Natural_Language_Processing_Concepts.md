<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<body>
<header>
<h1><a href="https://learn.microsoft.com/en-us/training/modules/introduction-language/">Natural Language Processing Fundamentals</a></h1>
</header>
<hr class="section-divider">
<main>
<section id="multiple-choice-questions">
        <section class="question-group">
            <h4>1. What is the primary focus of Natural Language Processing (NLP)?</h4>
            <ol type="a">
                <li>Analyzing numerical datasets</li>
                <li>Enabling computer systems to understand and respond to human language</li>
                <li>Designing graphic user interfaces</li>
                <li>Developing hardware components for AI</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>2. Text analysis is described as a part of NLP that focuses on:</h4>
            <ol type="a">
                <li>Creating new programming languages</li>
                <li>Extracting information from unstructured text</li>
                <li>Managing database systems</li>
                <li>Performing complex mathematical calculations</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>3. Which of the following is NOT listed as a common use case for NLP text analysis?</h4>
            <ol type="a">
                <li>Machine translation</li>
                <li>Speech-to-text conversion</li>
                <li>Hardware manufacturing</li>
                <li>Text classification</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>4. What historical challenge is mentioned regarding NLP before recent AI advancements?</h4>
            <ol type="a">
                <li>Lack of computational power</li>
                <li>The complexity and nuances of human language</li>
                <li>Absence of digital text data</li>
                <li>Insufficient interest from researchers</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>5. NLP is a field within which broader discipline?</h4>
            <ol type="a">
                <li>Data Warehousing</li>
                <li>Artificial Intelligence (AI)</li>
                <li>Web Development</li>
                <li>Network Security</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section
        <section class="question-group">
            <h4>6. What is the goal of 'speech-to-text' conversion in NLP?</h4>
            <ol type="a">
                <li>Converting written text into spoken words</li>
                <li>Transcribing spoken language into written text</li>
                <li>Analyzing the sentiment of spoken words</li>
                <li>Translating text between different languages</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>7. What is 'text-to-speech' conversion used for?</h4>
            <ol type="a">
                <li>Converting spoken language into written text</li>
                <li>Translating text from one language to another</li>
                <li>Synthesizing spoken words from written text</li>
                <li>Categorizing text documents</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>8. 'Machine translation' in NLP involves:</h4>
            <ol type="a">
                <li>Summarizing long texts</li>
                <li>Converting text from one natural language to another</li>
                <li>Extracting key entities from text</li>
                <li>Answering questions based on a given text</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>9. What is 'text classification' in NLP?</h4>
            <ol type="a">
                <li>Identifying the author of a text</li>
                <li>Assigning predefined categories or labels to text documents</li>
                <li>Converting text into speech</li>
                <li>Generating new text content</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>10. 'Entity extraction' (also known as Named Entity Recognition) in NLP aims to:</h4>
            <ol type="a">
                <li>Summarize the main ideas of a document</li>
                <li>Identify and classify named entities (like persons, organizations, locations) in text</li>
                <li>Translate text into different languages</li>
                <li>Convert speech into text</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>11. 'Question answering' in NLP is designed to:</h4>
            <ol type="a">
                <li>Generate questions from a given text</li>
                <li>Provide answers to questions based on information in a document or knowledge base</li>
                <li>Analyze the sentiment of questions</li>
                <li>Translate questions into different languages</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>12. What is 'text summarization' in NLP?</h4>
            <ol type="a">
                <li>Expanding a short text into a longer one</li>
                <li>Creating a concise and coherent summary of a longer text document</li>
                <li>Identifying keywords in a document</li>
                <li>Translating a document into a different language</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>13. Advancements in which field have significantly improved current NLP models?</h4>
            <ol type="a">
                <li>Traditional database management</li>
                <li>Basic data entry systems</li>
                <li>Artificial Intelligence (AI)</li>
                <li>Mechanical engineering</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>14. What does the introduction imply about the current state of NLP?</h4>
            <ol type="a">
                <li>It is still in its very early stages of development.</li>
                <li>It has overcome many historical challenges due to AI advancements.</li>
                <li>It is limited to only a few very specific applications.</li>
                <li>It requires manual programming for every task.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>15. Which aspect of language makes NLP challenging?</h4>
            <ol type="a">
                <li>Its rigid and unchanging rules</li>
                <li>Its simplicity and directness</li>
                <li>Its complexity, nuances, and ambiguity</li>
                <li>Its purely numerical nature</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>16. What is the primary method discussed for computers to analyze text?</h4>
            <ol type="a">
                <li>Manual human review of every word</li>
                <li>Statistical analysis of a body of text (corpus)</li>
                <li>Direct translation to machine code</li>
                <li>Graphical representation of text</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>17. What is a 'corpus' in the context of NLP?</h4>
            <ol type="a">
                <li>A single word in a document</li>
                <li>A large and structured collection of text documents</li>
                <li>A programming language for NLP</li>
                <li>A statistical technique</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>18. What is the first step in text analysis mentioned?</h4>
            <ol type="a">
                <li>Semantic modeling</li>
                <li>Tokenization</li>
                <li>Sentiment analysis</li>
                <li>Data visualization</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>19. What are 'tokens' in the context of tokenization?</h4>
            <ol type="a">
                <li>Entire sentences only</li>
                <li>Individual units of text, often words, but can be partial words or combinations with punctuation</li>
                <li>Numerical identifiers for documents</li>
                <li>Grammatical structures only</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>20. Which of the following is a key concept in tokenization for NLP?</h4>
            <ol type="a">
                <li>Hardware acceleration</li>
                <li>Text normalization</li>
                <li>Database indexing</li>
                <li>User interface design</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>21. What does 'text normalization' typically involve?</h4>
            <ol type="a">
                <li>Adding new words to the text</li>
                <li>Removing punctuation and converting text to lowercase</li>
                <li>Translating text into another language</li>
                <li>Summarizing the text content</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>22. What is a potential drawback of aggressive text normalization (e.g., removing all punctuation and converting to lowercase)?</h4>
            <ol type="a">
                <li>It makes the text longer</li>
                <li>It increases processing time</li>
                <li>It might lead to a loss of semantic meaning (e.g., "Mr Banks" vs. "banks")</li>
                <li>It makes it harder to count word frequencies</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>23. What is the purpose of 'stop word removal'?</h4>
            <ol type="a">
                <li>To include all words in the analysis</li>
                <li>To remove common words that add little semantic meaning (e.g., "the", "a", "it")</li>
                <li>To identify unique words in a document</li>
                <li>To correct spelling errors</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>24. What are 'n-grams'?</h4>
            <ol type="a">
                <li>Single characters in a text</li>
                <li>Multi-term phrases (e.g., "I have") that help models understand text better</li>
                <li>Numbers indicating word positions</li>
                <li>Graphical representations of text</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>25. What is a 'unigram'?</h4>
            <ol type="a">
                <li>A phrase with two words</li>
                <li>A single word</li>
                <li>A phrase with three words</li>
                <li>A sentence fragment</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>26. What does 'stemming' aim to achieve?</h4>
            <ol type="a">
                <li>To expand words into their full forms</li>
                <li>To consolidate words with the same root (e.g., "power", "powered", "powerful") into a single token</li>
                <li>To randomly change words in a text</li>
                <li>To translate words into a different language</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>27. When is 'text normalization' generally beneficial for NLP analyses?</h4>
            <ol type="a">
                <li>When preserving subtle semantic distinctions is critical</li>
                <li>When analyses rely heavily on exact word frequency counts</li>
                <li>When the source text contains many formal titles</li>
                <li>When dealing with very short texts only</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>28. Why are 'n-grams' important for machine learning models?</h4>
            <ol type="a">
                <li>They reduce the total number of words in a text.</li>
                <li>They help models better understand the context and relationships between words in a sequence.</li>
                <li>They simplify the language by removing complex terms.</li>
                <li>They make the data purely numerical.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>29. If you process the phrase "we choose to go to the moon" into tokens, how many distinct tokens are mentioned in the example?</h4>
            <ol type="a">
                <li>Four</li>
                <li>Five</li>
                <li>Six</li>
                <li>Seven</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>30. What is a 'bi-gram'?</h4>
            <ol type="a">
                <li>A single word</li>
                <li>A phrase consisting of two words</li>
                <li>A phrase consisting of three words</li>
                <li>A sentence with two clauses</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>31. Which two statistical techniques are highlighted as foundational for NLP?</h4>
            <ol type="a">
                <li>Regression and Classification</li>
                <li>Naïve Bayes and Term Frequency - Inverse Document Frequency (TF-IDF)</li>
                <li>Clustering and Dimensionality Reduction</li>
                <li>Markov Chains and Hidden Markov Models</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>32. Naïve Bayes was first used for what application?</h4>
            <ol type="a">
                <li>Image recognition</li>
                <li>Speech synthesis</li>
                <li>Email filtering (spam detection)</li>
                <li>Machine translation</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>33. How do Naïve Bayes classifiers typically identify spam emails?</h4>
            <ol type="a">
                <li>By analyzing the sender's IP address</li>
                <li>By identifying tokens (words) correlated with emails labeled as spam</li>
                <li>By checking the length of the email</li>
                <li>By looking for specific images in the email</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>34. What are 'bag-of-words' features in the context of Naïve Bayes?</h4>
            <ol type="a">
                <li>A collection of unrelated words</li>
                <li>A group of words that often occur together in a specific type of document</li>
                <li>Words that are visually represented as bags</li>
                <li>Words that are considered irrelevant</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>35. What was a limitation of Naïve Bayes compared to more advanced techniques?</h4>
            <ol type="a">
                <li>It was too slow for practical use.</li>
                <li>It only considered the presence of a word/token, not its position or context.</li>
                <li>It could only handle numerical data.</li>
                <li>It required a very small training dataset.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>36. What does TF-IDF stand for?</h4>
            <ol type="a">
                <li>Text Formation - Indexing Document Features</li>
                <li>Term Frequency - Inverse Document Frequency</li>
                <li>Tokenization Feature - Important Document Factors</li>
                <li>Topic Finding - Instance Document Filtering</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>37. How does TF-IDF compare the frequency of words?</h4>
            <ol type="a">
                <li>It only counts words in a single document.</li>
                <li>It compares the frequency of a word in one document with its frequency in a whole corpus of documents.</li>
                <li>It compares words based on their alphabetical order.</li>
                <li>It ignores word frequencies entirely.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>38. What is TF-IDF often used for?</h4>
            <ol type="a">
                <li>Generating new text content</li>
                <li>Synthesizing speech</li>
                <li>Information retrieval, to help understand which relative words to search for</li>
                <li>Translating languages</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>39. In TF-IDF, what characteristic leads to a high degree of relevance for a word?</h4>
            <ol type="a">
                <li>When it appears infrequently in a particular document and frequently across all documents.</li>
                <li>When it appears frequently in a particular document but relatively infrequently across a wide range of other documents.</li>
                <li>When it is a stop word.</li>
                <li>When it has a very long spelling.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>40. If simple frequency analysis (counting token occurrences) is effective for a single document, when do you need TF-IDF?</h4>
            <ol type="a">
                <li>When the document is very short.</li>
                <li>When you need to differentiate across multiple documents within the same corpus.</li>
                <li>When you want to identify grammatical errors.</li>
                <li>When you only care about the most common words.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>41. What is an example of a common spam word according to the Naïve Bayes example?</h4>
            <ol type="a">
                <li>"the"</li>
                <li>"miracle cure"</li>
                <li>"email"</li>
                <li>"document"</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>42. How did Naïve Bayes improve upon simple rule-based models for text classification?</h4>
            <ol type="a">
                <li>By ignoring all rules.</li>
                <li>By being more effective at identifying word correlations.</li>
                <li>By requiring more manual input.</li>
                <li>By only working for numerical data.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>43. What could be surmised from a text corpus if the most common bi-gram is "the moon"?</h4>
            <ol type="a">
                <li>The text is about lunar geography.</li>
                <li>The text is primarily concerned with space travel and going to the moon.</li>
                <li>The text is about astronomy in general.</li>
                <li>The text is a fairy tale.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>44. What does the "Term Frequency" part of TF-IDF measure?</h4>
            <ol type="a">
                <li>How often a term appears in the entire corpus.</li>
                <li>How often a term appears in a specific document.</li>
                <li>The importance of a term regardless of its frequency.</li>
                <li>The number of unique terms in a document.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>45. What does the "Inverse Document Frequency" part of TF-IDF measure?</h4>
            <ol type="a">
                <li>How rarely a term appears in a specific document.</li>
                <li>How unique or rare a term is across the entire corpus of documents.</li>
                <li>The total number of words in a document.</li>
                <li>The average length of terms.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
            <h4>46. What do deep learning language models use to encapsulate semantic relationships between tokens?</h4>
            <ol type="a">
                <li>Simple alphabetical sorting</li>
                <li>The number of characters in a word</li>
                <li>Vectors, known as embeddings</li>
                <li>Fixed rule-based dictionaries</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>47. What do 'embeddings' represent in a multidimensional space?</h4>
            <ol type="a">
                <li>The grammatical structure of sentences only</li>
                <li>The number of words in a document</li>
                <li>Direction and distance, where semantically similar tokens have vectors with similar orientations</li>
                <li>Random numerical values</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>48. According to the example, how do the vectors for "dog" and "bark" relate in terms of orientation?</h4>
            <ol type="a">
                <li>They point in opposite directions.</li>
                <li>They are entirely unrelated.</li>
                <li>They point in similar directions, indicating semantic similarity.</li>
                <li>One vector is much longer than the other.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>49. How do vectors for unrelated words like "dog" and "skateboard" appear?</h4>
            <ol type="a">
                <li>They point in similar directions.</li>
                <li>They point in entirely different directions.</li>
                <li>They overlap significantly.</li>
                <li>They are always the same length.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>50. What is true about industry-used language models regarding vectors?</h4>
            <ol type="a">
                <li>They only use 2-dimensional vectors.</li>
                <li>They use lower-dimensional vectors than simple examples.</li>
                <li>They are more complex and use higher-dimensional vectors.</li>
                <li>They do not use vectors at all.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>51. What can lead to different predictions from NLP models, even with the same data?</h4>
            <ol type="a">
                <li>Using the same method to calculate embeddings.</li>
                <li>Different methods used to calculate embeddings.</li>
                <li>Only the size of the corpus.</li>
                <li>The color of the text.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>52. What type of data is typically used to train language models for various NLP tasks?</h4>
            <ol type="a">
                <li>Only numerical data</li>
                <li>Labeled images</li>
                <li>A large corpus of raw text</li>
                <li>Pre-classified audio files</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>53. Which machine learning algorithm is specifically mentioned for text classification?</h4>
            <ol type="a">
                <li>K-Means Clustering</li>
                <li>Linear Regression</li>
                <li>Logistic Regression</li>
                <li>Support Vector Machine (SVM)</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>54. What is a common application of text classification mentioned in the context of semantic models?</h4>
            <ol type="a">
                <li>Generating new poems</li>
                <li>Translating text into different languages</li>
                <li>Sentiment analysis (classifying text as positive or negative)</li>
                <li>Predicting stock prices</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>55. In the restaurant review example, what does a label of '1' typically indicate?</h4>
            <ol type="a">
                <li>A negative review</li>
                <li>A neutral review</li>
                <li>A positive review</li>
                <li>An irrelevant review</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>56. How does a classification model learn the relationship between tokens and sentiment?</h4>
            <ol type="a">
                <li>By randomly assigning sentiments to tokens.</li>
                <li>By being trained on labeled data (e.g., reviews with positive/negative labels) to understand which words correlate with which sentiment.</li>
                <li>By only looking at the length of the review.</li>
                <li>By converting all words into numbers without any semantic consideration.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>57. What is the fundamental idea behind encoding language tokens as vectors?</h4>
            <ol type="a">
                <li>To make them shorter in length.</li>
                <li>To capture their semantic meaning and relationships in a numerical format.</li>
                <li>To hide their content from plain sight.</li>
                <li>To convert them into images.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>58. What happens to the 'raw text' in the generalized view of training language models?</h4>
            <ol type="a">
                <li>It is directly fed into the model without any changes.</li>
                <li>It is tokenized and then used to train the language models.</li>
                <li>It is discarded after initial reading.</li>
                <li>It is converted into images.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>59. If a review is labeled '0' in the sentiment analysis example, what does that signify?</h4>
            <ol type="a">
                <li>A positive sentiment</li>
                <li>A negative sentiment</li>
                <li>A neutral sentiment</li>
                <li>An error in labeling</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>60. What is the overall goal of semantic language models?</h4>
            <ol type="a">
                <li>To store large amounts of text data efficiently.</li>
                <li>To analyze text based on its literal word count.</li>
                <li>To enable computers to understand the meaning and context of human language.</li>
                <li>To provide a search engine for documents.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>61. Which characteristic of vectors is key to representing semantic relationships in embeddings?</h4>
            <ol type="a">
                <li>Their color</li>
                <li>Their alphabetical order</li>
                <li>Their orientation and distance in multidimensional space</li>
                <li>Their binary representation</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>62. Why are different methods for calculating embeddings used?</h4>
            <ol type="a">
                <li>To make the models slower.</li>
                <li>Because different approaches can capture different aspects of semantic relationships, leading to varied model predictions.</li>
                <li>To increase the computational cost.</li>
                <li>To reduce the size of the vocabulary.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>63. What kind of learning is text classification with labeled data (like sentiment analysis)?</h4>
            <ol type="a">
                <li>Unsupervised learning</li>
                <li>Reinforcement learning</li>
                <li>Supervised learning</li>
                <li>Transfer learning</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>64. What is implied by the term "semantic" in semantic language models?</h4>
            <ol type="a">
                <li>The models only process numerical data.</li>
                <li>The models are designed to understand the meaning and relationships of words and phrases.</li>
                <li>The models focus solely on grammatical correctness.</li>
                <li>The models are exclusively used for translation.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>65. Which words from the restaurant review example are indicative of positive sentiment?</h4>
            <ol type="a">
                <li>"terrible"</li>
                <li>"never"</li>
                <li>"great"</li>
                <li>"not"</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>66. What type of model learns to classify text based on known categorizations?</h4>
            <ol type="a">
                <li>A generative model</li>
                <li>A classification model</li>
                <li>A regression model</li>
                <li>A clustering model</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>67. The concept of embeddings is a bridge between which two representations of language?</h4>
            <ol type="a">
                <li>Visual and audio</li>
                <li>Symbolic (words) and numerical (vectors)</li>
                <li>Grammatical and phonetic</li>
                <li>Historical and modern</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>68. What is the advantage of using embeddings over simple word counts for semantic understanding?</h4>
            <ol type="a">
                <li>Embeddings are faster to compute.</li>
                <li>Embeddings capture contextual and semantic relationships, unlike simple word counts.</li>
                <li>Embeddings use less memory.</li>
                <li>Embeddings always result in higher accuracy without any training.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>69. In a general NLP pipeline, after tokenization, what typically follows as part of training language models?</h4>
            <ol type="a">
                <li>Direct deployment to users</li>
                <li>Applying deep learning techniques to learn semantic relationships and patterns</li>
                <li>Ignoring the tokens and generating random output</li>
                <li>Converting text to images</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>70. Which of the following is an example of a token that might have a similar embedding to "run"?</h4>
            <ol type="a">
                <li>"tree"</li>
                <li>"sprint"</li>
                <li>"car"</li>
                <li>"book"</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>71. What kind of dataset is essential for training text classification models like logistic regression?</h4>
            <ol type="a">
                <li>Unlabeled numerical data</li>
                <li>Randomly generated data</li>
                <li>Labeled datasets where text instances are associated with known categories</li>
                <li>Images with no associated text</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>72. What concept allows for representing words in a way that captures their meaning and relationship to other words?</h4>
            <ol type="a">
                <li>Token length</li>
                <li>Word count</li>
                <li>Embeddings</li>
                <li>Punctuation</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>73. What is the fundamental difference in purpose between TF-IDF and semantic language models (using embeddings)?</h4>
            <ol type="a">
                <li>TF-IDF focuses on semantic relationships, while embeddings focus on keyword frequency.</li>
                <li>TF-IDF focuses on term importance based on frequency and rarity, while semantic models aim to capture deeper contextual meaning.</li>
                <li>TF-IDF is for text generation, while semantic models are for text summarization.</li>
                <li>TF-IDF is a deep learning technique, while semantic models are statistical.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>74. What kind of neural networks are typically used to create high-dimensional embeddings in modern NLP?</h4>
            <ol type="a">
                <li>Simple perceptrons</li>
                <li>Shallow networks with few layers</li>
                <li>Deep neural networks (e.g., Transformers)</li>
                <li>Linear regression models</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>75. If "cat" and "meow" have similar vector orientations, what does this imply?</h4>
            <ol type="a">
                <li>They have the same spelling.</li>
                <li>They are semantically related.</li>
                <li>They are always found next to each other in text.</li>
                <li>They have the same grammatical function.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>76. What is the benefit of a model understanding semantic relationships?</h4>
            <ol type="a">
                <li>It can only recognize exact word matches.</li>
                <li>It can better understand context, meaning, and nuances, even if words are not identical.</li>
                <li>It reduces the need for any training data.</li>
                <li>It makes the model less accurate.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>77. What is a key difference between Naïve Bayes' 'bag-of-words' and semantic embeddings?</h4>
            <ol type="a">
                <li>Bag-of-words considers word position, while embeddings do not.</li>
                <li>Bag-of-words only counts word occurrences, while embeddings capture meaning and relationships.</li>
                <li>Bag-of-words is a deep learning technique, while embeddings are statistical.</li>
                <li>There is no significant difference.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>78. The complexity of industry-used language models suggests they:</h4>
            <ol type="a">
                <li>Are simpler to train than older models.</li>
                <li>Require less data than basic models.</li>
                <li>Are capable of handling more intricate language tasks and nuances.</li>
                <li>Only work for short sentences.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>79. Why is sentiment analysis a good example for explaining text classification?</h4>
            <ol type="a">
                <li>Because it always requires manual input.</li>
                <li>Because it's a clear binary or multi-class categorization task based on text content.</li>
                <li>Because it involves generating new text.</li>
                <li>Because it's a very simple problem that doesn't need machine learning.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>80. How do modern semantic models often learn their embeddings?</h4>
            <ol type="a">
                <li>Through manual dictionary creation.</li>
                <li>By being trained on large amounts of unlabeled text data in a self-supervised manner.</li>
                <li>By only using predefined rules.</li>
                <li>By requiring human labeling for every single word.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>81. What does it mean for tokens to have "similar orientations" in embedding space?</h4>
            <ol type="a">
                <li>They look similar graphically.</li>
                <li>They appear frequently together in documents.</li>
                <li>They share similar meanings or contexts.</li>
                <li>They are spelled similarly.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>82. Which aspect of text analysis is significantly enhanced by semantic models compared to purely statistical methods?</h4>
            <ol type="a">
                <li>Counting word frequencies</li>
                <li>Understanding the deeper meaning and context of words and sentences</li>
                <li>Identifying grammatical errors</li>
                <li>Removing stop words</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>83. What kind of problem is "classifying handwritten digits from 0 to 9" an example of?</h4>
            <ol type="a">
                <li>Regression</li>
                <li>Binary Classification</li>
                <li>Multiclass Classification</li>
                <li>Clustering</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>84. What happens if a word is very common across an entire corpus, according to TF-IDF?</h4>
            <ol type="a">
                <li>It will have a very high TF-IDF score.</li>
                <li>It will have a very low Inverse Document Frequency (IDF) component, thus lowering its overall TF-IDF score.</li>
                <li>It will be considered highly relevant to every document.</li>
                <li>It will be ignored by TF-IDF.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>85. How do semantic models typically process new, unseen text?</h4>
            <ol type="a">
                <li>They rely on human experts to label it first.</li>
                <li>They convert it into embeddings to understand its meaning in relation to previously learned knowledge.</li>
                <li>They only perform simple keyword matching.</li>
                <li>They cannot process unseen text.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>86. What is the broader implication of using semantic models for tasks like question answering?</h4>
            <ol type="a">
                <li>The system can only answer exact questions previously programmed.</li>
                <li>The system can understand the intent behind a question and retrieve relevant information, even if keywords don't match exactly.</li>
                <li>The system will only provide random answers.</li>
                <li>The system can only answer questions about simple facts.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>87. What is a key advantage of deep learning in NLP compared to earlier statistical methods?</h4>
            <ol type="a">
                <li>It requires less data.</li>
                <li>It can automatically learn complex features and representations from raw text without explicit feature engineering.</li>
                <li>It is always faster to train.</li>
                <li>It is less susceptible to overfitting.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>88. What does "unstructured text" refer to in NLP?</h4>
            <ol type="a">
                <li>Text that has no grammatical rules.</li>
                <li>Text that is organized in tables or databases.</li>
                <li>Text that does not have a predefined data model or organizational structure, like free-form sentences.</li>
                <li>Text that is only in numerical format.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>89. Why is understanding the 'context' of words crucial in NLP?</h4>
            <ol type="a">
                <li>It is not important; only individual words matter.</li>
                <li>Words can have different meanings depending on their context, and understanding context is essential for accurate interpretation.</li>
                <li>It only applies to very long documents.</li>
                <li>It makes the NLP models simpler.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>90. What kind of problem would be suitable for a model trained on a large corpus of medical research papers?</h4>
            <ol type="a">
                <li>Predicting daily weather</li>
                <li>Translating casual conversations</li>
                <li>Extracting medical entities and relationships from new research papers</li>
                <li>Generating random numbers</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>91. The evolution from Naïve Bayes to semantic models demonstrates a shift from:</h4>
            <ol type="a">
                <li>Ignoring word frequencies to solely relying on them.</li>
                <li>Simple frequency and presence-based analysis to understanding deeper meaning and context.</li>
                <li>Supervised to unsupervised learning only.</li>
                <li>Generating text to only classifying it.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>92. How does the dimensionality of vectors affect the complexity and capability of language models?</h4>
            <ol type="a">
                <li>Lower dimensionality always means higher capability.</li>
                <li>Higher dimensionality often allows models to capture more nuanced semantic relationships, but requires more computational resources.</li>
                <li>Dimensionality has no effect on model capability.</li>
                <li>Models only work with 1-dimensional vectors.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>93. What is the general idea of training a language model for "various NLP tasks"?</h4>
            <ol type="a">
                <li>Each task requires a completely separate model trained from scratch.</li>
                <li>A well-trained base language model can be adapted or fine-tuned for a wide range of specific NLP applications.</li>
                <li>Language models are only suitable for one type of task.</li>
                <li>Training a language model only prepares it for text summarization.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>94. What is a key component required for successful text classification using machine learning?</h4>
            <ol type="a">
                <li>Only unlabeled raw text.</li>
                <li>A clear definition of the categories to be classified.</li>
                <li>A physical dictionary for reference.</li>
                <li>Human intervention for every prediction.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>95. In the context of NLP, what does "generalized view" of language model training imply?</h4>
            <ol type="a">
                <li>A very specific, narrow approach to training.</li>
                <li>An overview of the common steps and principles applicable across many language model training scenarios.</li>
                <li>Only training on a small, niche dataset.</li>
                <li>Training only for a single language.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>96. What is the significance of the phrase "a large corpus of raw text" for training modern language models?</h4>
            <ol type="a">
                <li>It means the models only learn from a few select documents.</li>
                <li>It highlights that large amounts of diverse text data are crucial for models to learn rich language representations.</li>
                <li>It implies that the text must be pre-processed manually.</li>
                <li>It suggests that models cannot learn from raw text.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>97. When comparing "cat" and "meow" vs. "dog" and "skateboard" in embedding space, what is the core concept being illustrated?</h4>
            <ol type="a">
                <li>The length of words.</li>
                <li>The difference between semantically related and unrelated words.</li>
                <li>The number of vowels in words.</li>
                <li>The grammatical structure of phrases.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>98. What is the role of the training process in developing semantic models?</h4>
            <ol type="a">
                <li>To manually define all semantic relationships.</li>
                <li>To enable the model to learn the patterns and relationships within the text data, resulting in meaningful embeddings.</li>
                <li>To simply store the text without any analysis.</li>
                <li>To convert text into audio.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>99. What does the term 'tokens' ultimately represent once encoded as embeddings?</h4>
            <ol type="a">
                <li>Their original text form.</li>
                <li>Their position in a sentence.</li>
                <li>A rich, numerical representation of their meaning and context.</li>
                <li>A count of their occurrences.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: c)</p>
            </details>
        </section>
        <section class="question-group">
            <h4>100. Why are deep learning techniques essential for current semantic models?</h4>
            <ol type="a">
                <li>Because they are simpler than traditional statistical methods.</li>
                <li>Because they allow models to learn highly complex, hierarchical representations of language and automatically discover intricate semantic patterns from vast datasets.</li>
                <li>Because they do not require any data.</li>
                <li>Because they only work with small vocabularies.</li>
            </ol>
            <details>
                <summary>Show Answer</summary>
                <p>Correct Answer: b)</p>
            </details>
        </section>
    </section>
</main>
</body>
</html>
